{"componentChunkName":"component---src-templates-post-template-js","path":"/ruby-eventmachine-part-2-asynchronous-not-equal-faster","result":{"data":{"markdownRemark":{"id":"917f0336-b909-54ce-90f6-88a5e561223f","html":"<p>In this post I will look synchronous vs asynchronous programming with Ruby’s <a href=\"https://github.com/eventmachine/eventmachine\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">EventMachine</a>, to show that asynchronous does not always mean that your code will run faster.</p>\n<p>In <a href=\"/rubys-eventmachine-part-1-event-based-programming\">part 1</a> of this series on Ruby’s EventMachine I discussed the benefits of event-based programming in general. I am a big fan of event-based programming, as you will see in these posts, but I wanted to flip the coin over and look at one of the down-sides of event-based programming. </p>\n<h2 id=\"the-cost\" style=\"position:relative;\"><a href=\"#the-cost\" aria-label=\"the cost permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Cost</h2>\n<p>Managing events does not come for free. There is overhead of wrapping code in callbacks, stashing context, queuing events, deleting events, managing timer events and communication the the operating system.</p>\n<h2 id=\"exhibit-a\" style=\"position:relative;\"><a href=\"#exhibit-a\" aria-label=\"exhibit a permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Exhibit A</h2>\n<p>With the example I am using for this post, we talk over a TCP network connection and perform a high number of transactions in a short period of time. If you read <a href=\"/rubys-eventmachine-part-1-event-based-programming\">part 1</a>, then you will know that this sounds like an ideal use-case for EventMachine to really shine.</p>\n<p>The example I am going to use is Memcached. Memcached is fast. If you have a low-latency network connection to Memached, then it is really fast.</p>\n<p>Memcached, as its name implies, runs in memory, so the only thing that is going to slow it down is it being overwhelmed with network requests or some inefficiency in its algorithms (which are CPU bound). Personally, I have never hit the upper-bound of either of these, as there is always something else in the my architecture which croaks first.</p>\n<h2 id=\"the-test\" style=\"position:relative;\"><a href=\"#the-test\" aria-label=\"the test permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Test</h2>\n<p>I wrote a test to see if asynchronous memcached communication, using EventMachine, or synchronous memcached communication, using the <a href=\"https://github.com/evan/memcached/blob/master/README.rdoc\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">memcached</a> gem, would be faster.</p>\n<p>Here is the code…</p>\n<pre class=\"grvsc-container monokai\" data-language=\"ruby\" data-index=\"0\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">require</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;eventmachine&#39;</span><span class=\"mtk1\"> </span><span class=\"mtk3\"># for async</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">require</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;memcached&#39;</span><span class=\"mtk1\">    </span><span class=\"mtk3\"># for sync</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">require</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&#39;benchmark&#39;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">DEBUG </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">false</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">TEST_SIZE </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk4\">100_000</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">def</span><span class=\"mtk1\"> </span><span class=\"mtk5\">debug</span><span class=\"mtk1\"> </span><span class=\"mtk10 mtki\">msg</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> DEBUG</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    $stderr.</span><span class=\"mtk9\">puts</span><span class=\"mtk1\"> msg</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">def</span><span class=\"mtk1\"> </span><span class=\"mtk5\">async</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk9 mtki\">EM</span><span class=\"mtk1\">.run </span><span class=\"mtk7\">do</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    cache </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk9 mtki\">EventMachine</span><span class=\"mtk1\">::</span><span class=\"mtk9 mtki\">Protocols</span><span class=\"mtk1\">::</span><span class=\"mtk9 mtki\">Memcache</span><span class=\"mtk1\">.connect </span><span class=\"mtk6\">&#39;localhost&#39;</span><span class=\"mtk1\">, </span><span class=\"mtk4\">11211</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;sending SET requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      cache.set </span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\">, </span><span class=\"mtk6\">&quot;value</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\"> </span><span class=\"mtk7\">do</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        debug </span><span class=\"mtk6\">&quot;  SET key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;SET requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;sending GET requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      cache.get </span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\"> </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |value|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        debug </span><span class=\"mtk6\">&quot;  GET key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> = </span><span class=\"mtk7\">#{</span><span class=\"mtk1\">value</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;GET requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;sending DEL requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      cache.del(</span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\">) </span><span class=\"mtk7\">do</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        debug </span><span class=\"mtk6\">&quot;  DEL key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">if</span><span class=\"mtk1\"> n </span><span class=\"mtk7\">==</span><span class=\"mtk1\"> TEST_SIZE</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">          </span><span class=\"mtk9 mtki\">EM</span><span class=\"mtk1\">.stop</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">        </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">      </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;DEL requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">def</span><span class=\"mtk1\"> </span><span class=\"mtk5\">sync</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  cache </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> </span><span class=\"mtk9 mtki\">Memcached</span><span class=\"mtk1\">.</span><span class=\"mtk7\">new</span><span class=\"mtk1\">(</span><span class=\"mtk6\">&quot;localhost:11211&quot;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;sending SET requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    cache.set </span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\">, </span><span class=\"mtk6\">&quot;value</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;  SET key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;SET requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;sending GET requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    value </span><span class=\"mtk7\">=</span><span class=\"mtk1\"> cache.get </span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;  GET key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> = </span><span class=\"mtk7\">#{</span><span class=\"mtk1\">value</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;GET requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;sending DEL requests...&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  (</span><span class=\"mtk4\">1</span><span class=\"mtk1\">..TEST_SIZE).each </span><span class=\"mtk7\">do</span><span class=\"mtk1\"> |n|</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    cache.delete(</span><span class=\"mtk6\">&quot;key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\">&quot;</span><span class=\"mtk1\">)</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">    debug </span><span class=\"mtk6\">&quot;  DEL key</span><span class=\"mtk7\">#{</span><span class=\"mtk1\">n</span><span class=\"mtk7\">}</span><span class=\"mtk6\"> complete&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  </span><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk1\">  debug </span><span class=\"mtk6\">&quot;DEL requests sent&quot;</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk7\">end</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk9\">puts</span><span class=\"mtk1\"> </span><span class=\"mtk9 mtki\">Benchmark</span><span class=\"mtk1\">.measure { </span><span class=\"mtk9\">puts</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&quot;sync:&quot;</span><span class=\"mtk1\">;  sync  }</span></span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"><span class=\"mtk9\">puts</span><span class=\"mtk1\"> </span><span class=\"mtk9 mtki\">Benchmark</span><span class=\"mtk1\">.measure { </span><span class=\"mtk9\">puts</span><span class=\"mtk1\"> </span><span class=\"mtk6\">&quot;async:&quot;</span><span class=\"mtk1\">; async }</span></span></span></code></pre>\n<h2 id=\"the-results\" style=\"position:relative;\"><a href=\"#the-results\" aria-label=\"the results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Results</h2>\n<p>We are using <a href=\"https://ruby-doc.org/stdlib-1.9.3/libdoc/benchmark/rdoc/Benchmark.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">benchmark</a> to measure the time taken.</p>\n<pre class=\"grvsc-container monokai\" data-language=\"\" data-index=\"1\"><code class=\"grvsc-code\"><span class=\"grvsc-line\"><span class=\"grvsc-source\">$ ruby memcached.rb</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">sync:</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">  4.170000   4.360000   8.530000 ( 17.299242)</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\">async:</span></span>\n<span class=\"grvsc-line\"><span class=\"grvsc-source\"> 32.150000   0.990000  33.140000 ( 33.246160)</span></span></code></pre>\n<blockquote>\n<p>\nThis report shows the user CPU time, system CPU time, the sum of the user and system CPU times, and the elapsed real time. The unit of time is seconds. (from <a href=\"https://ruby-doc.org/stdlib-1.9.3/libdoc/benchmark/rdoc/Benchmark.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Benchmark docs</a>)</p>\n</blockquote>\n<p>So we can see from the above that EventMachine-based version took about twice as long to run, took 8 times as much user CPU time and over 4 times as much system CPU time. That is quite significant.</p>\n<h2 id=\"avoid-eventmachine-with-memcached\" style=\"position:relative;\"><a href=\"#avoid-eventmachine-with-memcached\" aria-label=\"avoid eventmachine with memcached permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Avoid EventMachine With Memcached?</h2>\n<p>This test needs to be put in context. The test was being run on same machine as Memcached, so the network latency was extremely low. EventMachine was not being used for anything else and this script had no other tasks to perform in-between sending requests to Memcached and receiving the responses, so blocking was not an issue.</p>\n<p>I could benchmark this and conclude that synchronous Memcached usage was the way to go. I would then roll it out to production, where Memcached is running on a different machine in a different data-center (please do not do this), and the latency would kill this synchronous script. Where you have latency and many requests, asynchronous event-based programming is usually going to win.</p>\n<p>Therefore, if the context is such that this kind of synchronous model works better for you, performance is important and you can be sure that things are not going to change, then <em>maybe</em> it is worth consideration.</p>\n<h2 id=\"suck-it-up\" style=\"position:relative;\"><a href=\"#suck-it-up\" aria-label=\"suck it up permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Suck It Up</h2>\n<p>Nearly everything application I write now is event-based. I use EventMachine in Ruby and Tornado’s <a href=\"https://www.tornadoweb.org/documentation/ioloop.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">io_loop</a> in Python. I write high performance code and do everything non-blocking, because I do not want anything to halt my event-loop, ever.</p>\n<p>I will gladly take a little overhead and fire up a new process or a new machine, if necessary, if it means that an external service like Memcached will not bring my event-loop to a halt when it has issues. It may be fast now, but one network glitch or Memcached crash may render my event-loop defunct. I might go from processing 10k requests per second to processing 1 per second, if I have a timeout of 1 second on one blocking network connection. So, yes, I will gladly suck up this asynchronous overhead in the short-term to protect from [expected] unexpected issues in the future.</p>\n<h2 id=\"can-eventmachine-be-faster\" style=\"position:relative;\"><a href=\"#can-eventmachine-be-faster\" aria-label=\"can eventmachine be faster permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Can EventMachine Be Faster?</h2>\n<p>I am a believer that anything can be better, faster, stronger. EventMachine is already heavily written in C++, which itself is a clear sign that its operation is CPU-bound.</p>\n<p>There is a pure ruby implementation of EventMachine. You can play with this to compare the performance of the C++ implementation. In basic tests, you unlikely see a difference. The general benefit you get with an event-based system, when dealing with latency in disk and network I/O, far out-weighs the overhead of the event-system. It is only when you start to hit it extremely hard you will see the differences.</p>\n<p>A faster EventMachine would be great, but it will make little difference to you when comparing with asynchronous code. You can never escape the overhead that asynchronous code adds. Therefore, synchronous code will continue to much look much faster in examples like the one above.</p>\n<p>Event-based programming enables your application to utilize 100% of the cpu, because anything not cpu-bound can be passed off to the operating system. Therefore, if our code-base is truly event-based, we would only see the benefit of a faster EventMachine once we hit 100% utilization of the CPU.</p>\n<p><strong>Side note:</strong> I have hit some bugs when using the pure-ruby implementation in my code and the EventMachine test-suite was not passing for me when trying to use pure-ruby. The test-suite is now passing with the latest HEAD of the <a href=\"https://github.com/eventmachine/eventmachine\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">git repository</a>, so these might have been a temporary issues, but it highlighted to me the order of priority for C++ vs pure-ruby implementations.</p>\n<h2 id=\"resources\" style=\"position:relative;\"><a href=\"#resources\" aria-label=\"resources permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resources</h2>\n<ul>\n<li><a href=\"https://groups.google.com/forum/?fromgroups=#!forum/eventmachine\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">EventMachine Mailing-list</a></li>\n</ul>\n<h2 id=\"rubys-eventmachine\" style=\"position:relative;\"><a href=\"#rubys-eventmachine\" aria-label=\"rubys eventmachine permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ruby’s EventMachine</h2>\n<p>Other posts in this series</p>\n<ul>\n<li><a href=\"/rubys-eventmachine-part-1-event-based-programming\">Part 1 : Event-based Programming</a></li>\n<li><a href=\"/ruby-eventmachine-part-2-asynchronous-not-equal-faster\">Part 2 : Asynchronous != Faster</a></li>\n</ul>\n<h2 id=\"comments\" style=\"position:relative;\"><a href=\"#comments\" aria-label=\"comments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Comments</h2>\n<div id=\"comments\">\n  <ol class=\"comment-list\">\n    <li id=\"comment-22146\" class=\"comment even thread-even depth-1 comment reader\">\n      <img alt=\"yuan\" src=\"https://0.gravatar.com/avatar/47081f2906ff164aadfa8eea575c4189?s=80&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n      <div class=\"comment-meta comment-meta-data\">\n        <div class=\"comment-author vcard\">\n          <cite class=\"fn\">yuan</cite>\n        </div>\n        <!-- .comment-author .vcard -->\n        <abbr class=\"comment-date\" title=\"Monday, September 24th, 2012, 7:56 pm\">September 24, 2012</abbr> at <abbr class=\"comment-time\" title=\"Monday, September 24th, 2012, 7:56 pm\">7:56 pm</abbr>\n      </div>\n      <div class=\"comment-text\">\n        <p>great!  how can I integrate eventmachine to my rails apps?</p>\n      </div>\n      <!-- .comment-text -->\n    </li>\n    <!-- .comment -->\n    <li id=\"comment-22151\" class=\"comment odd alt thread-odd thread-alt depth-1 comment reader\">\n      <img alt=\"Ludovic Henry\" src=\"https://0.gravatar.com/avatar/cfaf18c547ad83146d89bba7cdca1339?s=80&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n      <div class=\"comment-meta comment-meta-data\">\n        <div class=\"comment-author vcard\">\n          <cite class=\"fn\" title=\"https://ludovic-henry.com\">Ludovic Henry</cite>\n        </div>\n        <!-- .comment-author .vcard -->\n        <abbr class=\"comment-date\" title=\"Monday, September 24th, 2012, 10:48 pm\">September 24, 2012</abbr> at <abbr class=\"comment-time\" title=\"Monday, September 24th, 2012, 10:48 pm\">10:48 pm</abbr>\n      </div>\n      <div class=\"comment-text\">\n        <p>What are the results if you use epoll instead of select? Thank you.</p>\n      </div>\n      <!-- .comment-text -->\n      <ol class=\"children\">\n        <li id=\"comment-22286\" class=\"comment byuser comment-author-admin bypostauthor even depth-2 comment role-administrator user-admin entry-author\">\n          <img alt=\"Phil Whelan\" src=\"https://1.gravatar.com/avatar/5f357d996da96ccd36d3374e3728bf29?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n          <div class=\"comment-meta comment-meta-data\">\n            <div class=\"comment-author vcard\">\n              <cite class=\"fn\" title=\"https://www.google.com/profiles/101358683928607234715\">Phil Whelan</cite>\n            </div>\n            <!-- .comment-author .vcard -->\n            <abbr class=\"comment-date\" title=\"Thursday, September 27th, 2012, 10:53 am\">September 27, 2012</abbr> at <abbr class=\"comment-time\" title=\"Thursday, September 27th, 2012, 10:53 am\">10:53 am</abbr>\n          </div>\n          <div class=\"comment-text\">\n            <p>Hi Ludovic,</p>\n            <p>I added EM.epoll before EM.run and here are the results</p>\n            <pre>$ ruby memcached.rb\nsync:\n  3.950000   4.240000   8.190000 ( 16.496183)\nasync:\n 40.090000   1.110000  41.200000 ( 41.708882)</pre>\n            <p>Actually a little worse performance, but this is running on my Mac and epoll is for multiplexed I/O that is available in Linux 2.6 kernels.</p>\n            <p>Cheers,<br>\nPhil</p>\n          </div>\n          <!-- .comment-text -->\n          <ol class=\"children\">\n            <li id=\"comment-22319\" class=\"comment odd alt depth-3 comment reader\">\n              <img alt=\"Ludovic Henry\" src=\"https://0.gravatar.com/avatar/cfaf18c547ad83146d89bba7cdca1339?s=80&amp;d=https%3A%2F%2F0.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n              <div class=\"comment-meta comment-meta-data\">\n                <div class=\"comment-author vcard\">\n                  <cite class=\"fn\" title=\"https://ludovic-henry.com\">Ludovic Henry</cite>\n                </div>\n                <!-- .comment-author .vcard -->\n                <abbr class=\"comment-date\" title=\"Friday, September 28th, 2012, 1:19 am\">September 28, 2012</abbr> at <abbr class=\"comment-time\" title=\"Friday, September 28th, 2012, 1:19 am\">1:19 am</abbr>\n              </div>\n              <div class=\"comment-text\">\n                <p>If you are using OS/X &#x2013; BSD, you should be using kqueue with &#x201C;EM.kqueue = true if EM.kqueue?&#x201D;.</p>\n                <p>About Epoll, if it&#x2019;s not available on the platform (not on linux2.6+), it should fallback to select..</p>\n              </div>\n              <!-- .comment-text -->\n            </li>\n            <!-- .comment -->\n          </ol>\n        </li>\n        <!-- .comment -->\n      </ol>\n    </li>\n    <!-- .comment -->\n    <li id=\"comment-22451\" class=\"comment even thread-even depth-1 comment reader\">\n      <img alt=\"Phil Pirozhkov\" src=\"https://1.gravatar.com/avatar/bb3cf80b7af6b40db1b3b2445ee738a1?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n      <div class=\"comment-meta comment-meta-data\">\n        <div class=\"comment-author vcard\">\n          <cite class=\"fn\">Phil Pirozhkov</cite>\n        </div>\n        <!-- .comment-author .vcard -->\n        <abbr class=\"comment-date\" title=\"Sunday, September 30th, 2012, 3:45 pm\">September 30, 2012</abbr> at <abbr class=\"comment-time\" title=\"Sunday, September 30th, 2012, 3:45 pm\">3:45 pm</abbr>\n      </div>\n      <div class=\"comment-text\">\n        <p>It&#x2019;s a very good example that EM is still far from being perfect.<br>\nThis is mostly due to the poor memcached protocol implementation, which adds all these callbacks to an array and is poping it one by one.</p>\n        <p>There&#x2019;s a problem in test itself, you should consider that in evented style you never know which operation finishes first, and you cannot be sure that DEL is sent after SET and GET. So this should be better:</p>\n        <div class=\"CodeRay\">\n          <div class=\"code\">\n            <pre>require &apos;em-synchrony&apos;\nrequire &apos;em-synchrony/em-memcache&apos;\ndef async2\n  EventMachine.synchrony do\n    cache = EM::P::Memcache.connect\n    TEST_SIZE.times do |n|\n      cache.set &quot;key#{n}&quot;, &quot;value#{n}&quot;\n    end\n    TEST_SIZE.times do |n|\n      value = cache.get &quot;key#{n}&quot;\n    end\n    TEST_SIZE.times do |n|\n      cache.delete(&quot;key#{n}&quot;)\n    end\n    EventMachine.stop\n  end\nend\nputs Benchmark.measure { puts &quot;async:&quot;; async2 }\n</pre>\n          </div>\n        </div>\n        <p>However, the overhead is the same.</p>\n      </div>\n      <!-- .comment-text -->\n      <ol class=\"children\">\n        <li id=\"comment-22455\" class=\"comment odd alt depth-2 comment reader\">\n          <img alt=\"Phil Pirozhkov\" src=\"https://1.gravatar.com/avatar/bb3cf80b7af6b40db1b3b2445ee738a1?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n          <div class=\"comment-meta comment-meta-data\">\n            <div class=\"comment-author vcard\">\n              <cite class=\"fn\">Phil Pirozhkov</cite>\n            </div>\n            <!-- .comment-author .vcard -->\n            <abbr class=\"comment-date\" title=\"Sunday, September 30th, 2012, 4:29 pm\">September 30, 2012</abbr> at <abbr class=\"comment-time\" title=\"Sunday, September 30th, 2012, 4:29 pm\">4:29 pm</abbr>\n          </div>\n          <div class=\"comment-text\">\n            <p>Forgot to mention that on my machine sync is only 50%-100% faster than async given your benchmark. (2 cores, linux 3.5.4).</p>\n          </div>\n          <!-- .comment-text -->\n        </li>\n        <!-- .comment -->\n      </ol>\n    </li>\n    <!-- .comment -->\n    <li id=\"comment-22538\" class=\"comment even thread-odd thread-alt depth-1 comment reader\">\n      <img alt=\"Jarmo Pertman\" src=\"https://1.gravatar.com/avatar/ff97ca87af59ee68ceff5877a8365788?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n      <div class=\"comment-meta comment-meta-data\">\n        <div class=\"comment-author vcard\">\n          <cite class=\"fn\" title=\"https://itreallymatters.net\">Jarmo Pertman</cite>\n        </div>\n        <!-- .comment-author .vcard -->\n        <abbr class=\"comment-date\" title=\"Thursday, October 4th, 2012, 10:54 am\">October 4, 2012</abbr> at <abbr class=\"comment-time\" title=\"Thursday, October 4th, 2012, 10:54 am\">10:54 am</abbr>\n      </div>\n      <div class=\"comment-text\">\n        <p>You could also try Benchmark.bmbm instead of .measure to see if there&#x2019;s any effect when having also the rehearsal phase.</p>\n      </div>\n      <!-- .comment-text -->\n    </li>\n    <!-- .comment -->\n    <li id=\"comment-24355\" class=\"comment odd alt thread-even depth-1 comment reader\">\n      <img alt=\"Nicol&#xE1;s\" src=\"https://1.gravatar.com/avatar/d26aa7a45965be73497f83347f1800f8?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n      <div class=\"comment-meta comment-meta-data\">\n        <div class=\"comment-author vcard\">\n          <cite class=\"fn\">Nicol&#xE1;s</cite>\n        </div>\n        <!-- .comment-author .vcard -->\n        <abbr class=\"comment-date\" title=\"Tuesday, October 30th, 2012, 6:18 am\">October 30, 2012</abbr> at <abbr class=\"comment-time\" title=\"Tuesday, October 30th, 2012, 6:18 am\">6:18 am</abbr>\n      </div>\n      <div class=\"comment-text\">\n        <p>Greate post! Waiting for part 3!!!</p>\n      </div>\n      <!-- .comment-text -->\n      <ol class=\"children\">\n        <li id=\"comment-24376\" class=\"comment byuser comment-author-admin bypostauthor even depth-2 comment role-administrator user-admin entry-author\">\n          <img alt=\"Phil Whelan\" src=\"https://1.gravatar.com/avatar/5f357d996da96ccd36d3374e3728bf29?s=80&amp;d=https%3A%2F%2F1.gravatar.com%2Favatar%2Fad516503a11cd5ca435acc9bb6523536%3Fs%3D80&amp;r=PG\" class=\"avatar avatar-80 photo\" height=\"80\" width=\"80\">\n          <div class=\"comment-meta comment-meta-data\">\n            <div class=\"comment-author vcard\">\n              <cite class=\"fn\" title=\"https://www.google.com/profiles/101358683928607234715\">Phil Whelan</cite>\n            </div>\n            <!-- .comment-author .vcard -->\n            <abbr class=\"comment-date\" title=\"Tuesday, October 30th, 2012, 2:43 pm\">October 30, 2012</abbr> at <abbr class=\"comment-time\" title=\"Tuesday, October 30th, 2012, 2:43 pm\">2:43 pm</abbr>\n          </div>\n          <div class=\"comment-text\">\n            <p>Be careful what you wish for&#x2026;<br>\n<a href=\"/rubys-eventmachine-part-3-thin\">Ruby&#x2019;s EventMachine &#x2013; Part 3 : Thin</a></p>\n          </div>\n          <!-- .comment-text -->\n        </li>\n        <!-- .comment -->\n      </ol>\n    </li>\n    <!-- .comment -->\n  </ol>\n  <!-- .comment-list -->\n</div>\n<style class=\"grvsc-styles\">\n  .grvsc-container {\n    overflow: auto;\n    position: relative;\n    -webkit-overflow-scrolling: touch;\n    padding-top: 1rem;\n    padding-top: var(--grvsc-padding-top, var(--grvsc-padding-v, 1rem));\n    padding-bottom: 1rem;\n    padding-bottom: var(--grvsc-padding-bottom, var(--grvsc-padding-v, 1rem));\n    border-radius: 8px;\n    border-radius: var(--grvsc-border-radius, 8px);\n    font-feature-settings: normal;\n    line-height: 1.4;\n  }\n  \n  .grvsc-code {\n    display: table;\n  }\n  \n  .grvsc-line {\n    display: table-row;\n    box-sizing: border-box;\n    width: 100%;\n    position: relative;\n  }\n  \n  .grvsc-line > * {\n    position: relative;\n  }\n  \n  .grvsc-gutter-pad {\n    display: table-cell;\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  .grvsc-gutter {\n    display: table-cell;\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter::before {\n    content: attr(data-content);\n  }\n  \n  .grvsc-source {\n    display: table-cell;\n    padding-left: 1.5rem;\n    padding-left: var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem));\n    padding-right: 1.5rem;\n    padding-right: var(--grvsc-padding-right, var(--grvsc-padding-h, 1.5rem));\n  }\n  \n  .grvsc-source:empty::after {\n    content: ' ';\n    -webkit-user-select: none;\n    -moz-user-select: none;\n    user-select: none;\n  }\n  \n  .grvsc-gutter + .grvsc-source {\n    padding-left: 0.75rem;\n    padding-left: calc(var(--grvsc-padding-left, var(--grvsc-padding-h, 1.5rem)) / 2);\n  }\n  \n  /* Line transformer styles */\n  \n  .grvsc-has-line-highlighting > .grvsc-code > .grvsc-line::before {\n    content: ' ';\n    position: absolute;\n    width: 100%;\n  }\n  \n  .grvsc-line-diff-add::before {\n    background-color: var(--grvsc-line-diff-add-background-color, rgba(0, 255, 60, 0.2));\n  }\n  \n  .grvsc-line-diff-del::before {\n    background-color: var(--grvsc-line-diff-del-background-color, rgba(255, 0, 20, 0.2));\n  }\n  \n  .grvsc-line-number {\n    padding: 0 2px;\n    text-align: right;\n    opacity: 0.7;\n  }\n  \n  .monokai {\n    background-color: #272822;\n    color: #f8f8f2;\n  }\n  .monokai .mtki { font-style: italic; }\n  .monokai .mtk7 { color: #F92672; }\n  .monokai .mtk1 { color: #F8F8F2; }\n  .monokai .mtk6 { color: #E6DB74; }\n  .monokai .mtk3 { color: #75715E; }\n  .monokai .mtk4 { color: #AE81FF; }\n  .monokai .mtk5 { color: #A6E22E; }\n  .monokai .mtk10 { color: #FD971F; }\n  .monokai .mtk9 { color: #66D9EF; }\n  .monokai .grvsc-line-highlighted::before {\n    background-color: var(--grvsc-line-highlighted-background-color, rgba(255, 255, 255, 0.1));\n    box-shadow: inset var(--grvsc-line-highlighted-border-width, 4px) 0 0 0 var(--grvsc-line-highlighted-border-color, rgba(255, 255, 255, 0.5));\n  }\n</style>","fields":{"slug":"/ruby-eventmachine-part-2-asynchronous-not-equal-faster","tagSlugs":["/tag/asynchronous/","/tag/benchmark/","/tag/event-loop/","/tag/eventmachine/","/tag/fast/","/tag/memcached/","/tag/ruby/","/tag/synchronous/","/tag/tornado/"]},"frontmatter":{"date":"2012-09-24T13:19:00-07:00","description":"In this post I will look synchronous vs asynchronous programming with Ruby's EventMachine, to show that asynchronous does not always mean that your code will run faster. In part 1 of this series on Ruby's EventMachine I discussed the benefits of event-based programming in general. I am a big fan of event-based programming, as you will see in these posts, but I wanted to flip the coin over and look at one of the down-sides of event-based programming.","tags":["asynchronous","benchmark","event-loop","eventmachine","fast","memcached","ruby","synchronous","tornado"],"title":"Ruby’s EventMachine – Part 2 : Asynchronous != Faster","socialImage":null}}},"pageContext":{"slug":"/ruby-eventmachine-part-2-asynchronous-not-equal-faster"}},"staticQueryHashes":["251939775","3942705351","401334301"]}