<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
		>
<channel>
	<title>Comments on: Working With Large Data Sets</title>
	<atom:link href="http://www.bigfastblog.com/working-with-large-data-sets/feed" rel="self" type="application/rss+xml" />
	<link>http://www.bigfastblog.com/working-with-large-data-sets</link>
	<description>Big Fast Technology</description>
	<lastBuildDate>Mon, 05 May 2014 08:14:53 +0000</lastBuildDate>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.0.1</generator>
	<item>
		<title>By: Phil Whelan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-492</link>
		<dc:creator>Phil Whelan</dc:creator>
		<pubDate>Mon, 27 Dec 2010 04:10:39 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-492</guid>
		<description>Thanks Montreal Web Design. Here&#039;s a link for anyone interested http://s4.io/</description>
		<content:encoded><![CDATA[<p>Thanks Montreal Web Design. Here&#8217;s a link for anyone interested <a href="http://s4.io/" rel="nofollow">http://s4.io/</a></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Montreal Web Design</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-489</link>
		<dc:creator>Montreal Web Design</dc:creator>
		<pubDate>Mon, 27 Dec 2010 03:37:36 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-489</guid>
		<description>You might want to look at s4 by Yahoo. They recently open-sourced it.</description>
		<content:encoded><![CDATA[<p>You might want to look at s4 by Yahoo. They recently open-sourced it.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Working with large data sets &#171; Hansa-Cequity&#039;s Knowledge Centre</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-161</link>
		<dc:creator>Working with large data sets &#171; Hansa-Cequity&#039;s Knowledge Centre</dc:creator>
		<pubDate>Mon, 29 Nov 2010 13:32:37 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-161</guid>
		<description>[...] Take a look           LikeBe the first to like this post. [...]</description>
		<content:encoded><![CDATA[<p>[...] Take a look           LikeBe the first to like this post. [...]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Data Mining Without Hadoop</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-64</link>
		<dc:creator>Data Mining Without Hadoop</dc:creator>
		<pubDate>Thu, 30 Sep 2010 21:41:11 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-64</guid>
		<description>[...] is a follow-up to my recent blog-post on Working With Large Data Sets. That post had some interest, so I thought it would be a good idea to go through the methodologies [...]</description>
		<content:encoded><![CDATA[<p>[...] is a follow-up to my recent blog-post on Working With Large Data Sets. That post had some interest, so I thought it would be a good idea to go through the methodologies [...]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Working With Large Data Sets &#124; Large Data Matters</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-58</link>
		<dc:creator>Working With Large Data Sets &#124; Large Data Matters</dc:creator>
		<pubDate>Mon, 27 Sep 2010 17:58:15 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-58</guid>
		<description>[...] post on Large Data Sets.   This entry was posted in General. Bookmark the permalink.    &#8592; Webinar [...]</description>
		<content:encoded><![CDATA[<p>[...] post on Large Data Sets.   This entry was posted in General. Bookmark the permalink.    &larr; Webinar [...]</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Phil Whelan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-57</link>
		<dc:creator>Phil Whelan</dc:creator>
		<pubDate>Mon, 27 Sep 2010 15:09:18 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-57</guid>
		<description>Thanks Michael. Hopefully Toronto will catch up with the technological juggernaut that Vancouver is.

On a serious note, MailChannels is developing some very cool stuff in the anti-spam space. They&#039;re expanding the development team right now, so if there is anyone in Vancouver interested, you should pop in and say hi.</description>
		<content:encoded><![CDATA[<p>Thanks Michael. Hopefully Toronto will catch up with the technological juggernaut that Vancouver is.</p>
<p>On a serious note, MailChannels is developing some very cool stuff in the anti-spam space. They&#8217;re expanding the development team right now, so if there is anyone in Vancouver interested, you should pop in and say hi.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Michael Fever</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-56</link>
		<dc:creator>Michael Fever</dc:creator>
		<pubDate>Mon, 27 Sep 2010 06:36:31 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-56</guid>
		<description>Thats awesome, congratulations. It’s really refreshing to see these kinds of innovations coming out of Canada, even it if it Vancouver and not Toronto lol =)</description>
		<content:encoded><![CDATA[<p>Thats awesome, congratulations. It’s really refreshing to see these kinds of innovations coming out of Canada, even it if it Vancouver and not Toronto lol =)</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Phil Whelan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-54</link>
		<dc:creator>Phil Whelan</dc:creator>
		<pubDate>Sun, 26 Sep 2010 18:35:10 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-54</guid>
		<description>Hi Antti,

My experience, from working with our customers at MailChannels, was that grey-listing started to become ineffective a couple of years ago as the spambot writers started to incorporate this technology into their software and perform retries, just as a legitimate email server would. Not actually having worked with grey-listing myself, I do have any hard figures to back-up conversations with customers, who sometimes became our customers whilst looking for alternatives to grey-listing.

You are obviously an expert in this area, so I would be really interested in any statistics or other data you have on the effectiveness of grey-listing. Do you have a blog?

Thanks,
Phil</description>
		<content:encoded><![CDATA[<p>Hi Antti,</p>
<p>My experience, from working with our customers at MailChannels, was that grey-listing started to become ineffective a couple of years ago as the spambot writers started to incorporate this technology into their software and perform retries, just as a legitimate email server would. Not actually having worked with grey-listing myself, I do have any hard figures to back-up conversations with customers, who sometimes became our customers whilst looking for alternatives to grey-listing.</p>
<p>You are obviously an expert in this area, so I would be really interested in any statistics or other data you have on the effectiveness of grey-listing. Do you have a blog?</p>
<p>Thanks,<br />
Phil</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Antti Siira</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-52</link>
		<dc:creator>Antti Siira</dc:creator>
		<pubDate>Sat, 25 Sep 2010 15:16:53 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-52</guid>
		<description>If you want to see bloom filters used in spam processing, you could check out gross[1] that uses them for greylisting. It has proven[2] itself quite efficient way to block large amount of spam.

[1] http://code.google.com/p/gross/ 
[2] https://lists.utu.fi/pipermail/gross/2007/000035.html</description>
		<content:encoded><![CDATA[<p>If you want to see bloom filters used in spam processing, you could check out gross[1] that uses them for greylisting. It has proven[2] itself quite efficient way to block large amount of spam.</p>
<p>[1] <a href="http://code.google.com/p/gross/" rel="nofollow">http://code.google.com/p/gross/</a><br />
[2] <a href="https://lists.utu.fi/pipermail/gross/2007/000035.html" rel="nofollow">https://lists.utu.fi/pipermail/gross/2007/000035.html</a></p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Phil Whelan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-45</link>
		<dc:creator>Phil Whelan</dc:creator>
		<pubDate>Fri, 24 Sep 2010 15:47:30 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-45</guid>
		<description>Hi Alan,

Thank you for the comment. The Bloom Filter does sound like a great tool, that I&#039;ve not come across before. I will have to read up on it.

In this case, where the goal is to build concrete statistics, I think the false-positive aspect of the Bloom Filter would have affected the results. Even if it was ever so slightly, I would have felt uncomfortable publishing them and referring to somebody else&#039;s technology (Spamhaus in this case) where I knew there may be a slight inaccuracy.

I see that the Bloom Filter addresses memory consumption. Since I had so much data, memory was not an issue. That&#039;s sounds backwards and it is. Since the data cannot possibly fit into a machine memory, I used several technics I discovered from working with Hadoop. Basically streaming data to and from disk in the most efficient way, performing several transformations of the data and writing the data to disk to divide, organise, sort, merge and conquer. I think the peak memory I used was far less than I had on the machine, and this was generally highest when sorting the individual files.

I&#039;m considering writing a blog post on the details of how I tackled this data, as this blog post proved to be quite popular. Would that be something you would be interested in?</description>
		<content:encoded><![CDATA[<p>Hi Alan,</p>
<p>Thank you for the comment. The Bloom Filter does sound like a great tool, that I&#8217;ve not come across before. I will have to read up on it.</p>
<p>In this case, where the goal is to build concrete statistics, I think the false-positive aspect of the Bloom Filter would have affected the results. Even if it was ever so slightly, I would have felt uncomfortable publishing them and referring to somebody else&#8217;s technology (Spamhaus in this case) where I knew there may be a slight inaccuracy.</p>
<p>I see that the Bloom Filter addresses memory consumption. Since I had so much data, memory was not an issue. That&#8217;s sounds backwards and it is. Since the data cannot possibly fit into a machine memory, I used several technics I discovered from working with Hadoop. Basically streaming data to and from disk in the most efficient way, performing several transformations of the data and writing the data to disk to divide, organise, sort, merge and conquer. I think the peak memory I used was far less than I had on the machine, and this was generally highest when sorting the individual files.</p>
<p>I&#8217;m considering writing a blog post on the details of how I tackled this data, as this blog post proved to be quite popular. Would that be something you would be interested in?</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Alan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-43</link>
		<dc:creator>Alan</dc:creator>
		<pubDate>Fri, 24 Sep 2010 08:08:04 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-43</guid>
		<description>@Phil excellent post. I appreciate the problems you face when dealing with extremely high numbers in a short space of time.  Your distributed search with Lucene sounds interesting.  Would love to hear more about that in future.

One method we use with extreme effectiveness is the use of the data structure, BloomFilter.  This data structure is an extremely effective tool for determining if you have seen something before without any expensive database or search lookup.   It is the technology a lot of the big hash map implementations use internally.</description>
		<content:encoded><![CDATA[<p>@Phil excellent post. I appreciate the problems you face when dealing with extremely high numbers in a short space of time.  Your distributed search with Lucene sounds interesting.  Would love to hear more about that in future.</p>
<p>One method we use with extreme effectiveness is the use of the data structure, BloomFilter.  This data structure is an extremely effective tool for determining if you have seen something before without any expensive database or search lookup.   It is the technology a lot of the big hash map implementations use internally.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: Phil Whelan</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-42</link>
		<dc:creator>Phil Whelan</dc:creator>
		<pubDate>Thu, 23 Sep 2010 21:18:57 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-42</guid>
		<description>Well, if you have a technology that you intend to sell, then you need to talk about it, and the bad guys usually figure it out quickly enough anyway. Actually, I&#039;ve recently moved on from MailChannels to start my own tech company, so I&#039;m not trying to sell the technology right now. Without getting into too much detail, slowing connections targets the economics of sending spam. Spammers have to get an enormous amount of spam out to get enough people to click on the links or buy of the controversial pharmaceuticals that they are selling. Their click-through-rate is incredibly small. Even if they know you are slowing them down, they do not have the time to wait around. It&#039;s better for them to move onto the next guy.

My approach to starting a tech company is getting things up and running as quickly as possible. Use the languages and tools that you are most comfortable with. You do not need to scale until you are successful, at which point it&#039;s easier to rewrite things in a more scalable way, or hire somebody else who knows how to do it, and concentrate on putting out the other fires in your successful business. You&#039;ll probably be rewriting things anyway as the product or service evolves and you learn more about the need that you are addressing. When you make things scalable you lock yourself into certain choices that limits your ability to be dynamic.</description>
		<content:encoded><![CDATA[<p>Well, if you have a technology that you intend to sell, then you need to talk about it, and the bad guys usually figure it out quickly enough anyway. Actually, I&#8217;ve recently moved on from MailChannels to start my own tech company, so I&#8217;m not trying to sell the technology right now. Without getting into too much detail, slowing connections targets the economics of sending spam. Spammers have to get an enormous amount of spam out to get enough people to click on the links or buy of the controversial pharmaceuticals that they are selling. Their click-through-rate is incredibly small. Even if they know you are slowing them down, they do not have the time to wait around. It&#8217;s better for them to move onto the next guy.</p>
<p>My approach to starting a tech company is getting things up and running as quickly as possible. Use the languages and tools that you are most comfortable with. You do not need to scale until you are successful, at which point it&#8217;s easier to rewrite things in a more scalable way, or hire somebody else who knows how to do it, and concentrate on putting out the other fires in your successful business. You&#8217;ll probably be rewriting things anyway as the product or service evolves and you learn more about the need that you are addressing. When you make things scalable you lock yourself into certain choices that limits your ability to be dynamic.</p>
]]></content:encoded>
	</item>
	<item>
		<title>By: SL</title>
		<link>http://www.bigfastblog.com/working-with-large-data-sets/comment-page-1#comment-41</link>
		<dc:creator>SL</dc:creator>
		<pubDate>Thu, 23 Sep 2010 21:04:03 +0000</pubDate>
		<guid isPermaLink="false">http://www.bigfastblog.com/?p=149#comment-41</guid>
		<description>Very cool stuff. I&#039;ve always been hesitant to blog about anti-spam for fear of spammers picking up on it and modifying their techniques. Are you concerned that spammers might do that in this case?

I&#039;m just starting a tech company and hope to be dealing with large data sets. It&#039;s a balance between planning for the future and acting now. If there&#039;s no action now, there&#039;s not future but without planning the future will be disastrous.</description>
		<content:encoded><![CDATA[<p>Very cool stuff. I&#8217;ve always been hesitant to blog about anti-spam for fear of spammers picking up on it and modifying their techniques. Are you concerned that spammers might do that in this case?</p>
<p>I&#8217;m just starting a tech company and hope to be dealing with large data sets. It&#8217;s a balance between planning for the future and acting now. If there&#8217;s no action now, there&#8217;s not future but without planning the future will be disastrous.</p>
]]></content:encoded>
	</item>
</channel>
</rss>
<!-- WP Super Cache is installed but broken. The path to wp-cache-phase1.php in wp-content/advanced-cache.php must be fixed! -->